---
permalink: /
title: "About"
excerpt: "Alexandra Chronopoulou"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I am Alexandra, a Research Scientist at Google DeepMind in the GenAI team working on post-training of LLMs (Gemini) and more widely on Natural Language Processing (Machine Learning). 

I earned my PhD in Computer Science from the [University of Munich](https://www.en.uni-muenchen.de/index.html), where I was advised by [Alex Fraser](https://www.cis.uni-muenchen.de/~fraser/). My PhD research was mostly on combining information from various languages and domains to enable positive transfer during parameter-efficient fine-tuning of language models, especially under resource constraints.   

<!-- machine translation, multilinguality and domain adaptation. I am currently interested in parameter-efficient fine-tuning methods; I am particularly excited about combining information from different languages, domains or tasks to enable positive transfer using modular approaches. -->

During my PhD, I interned at [Google DeepÎœind](https://www.deepmind.com/) in Berlin, hosted by [Sebastian Ruder](https://www.ruder.io/) and [Priyanka Agrawal](https://sites.google.com/site/priyankaagr17). Prior to that, I interned (twice) at the [Allen Institute for AI](https://allenai.org/) with [Jesse Dodge](https://jessedodge.github.io/) and [Matt Peters](https://scholar.google.com/citations?user=K5nCPZwAAAAJ&hl=en); I was part of the [AllenNLP](https://allenai.org/allennlp) team. I also spent a few months at [Amazon AI](https://aws.amazon.com/machine-learning/) in Santa Clara, CA , working with [Brian Thompson](https://thompsonb.github.io/), [Prashant Mathur](http://mtresearcher.github.io/) and [Marcello Federico](https://www.marcellofederico.net) as an intern in the AI human language technology group.

Before starting the PhD, I graduated with a diploma (Bachelor and MEng) in [Electrical & Computer Engineering](https://www.ece.ntua.gr/en) from the [National Technical University of Athens (NTUA)](https://www.ntua.gr/en/). 



 <h2>News</h2>
 
<b>August 2025</b>: I will be in San Diego in December to attend NeurIPS and participate at the panel of the [Model Merging](https://neurips.cc/virtual/2025/tutorial/109593) tutorial.

  <b>July 2025</b>: The [technical report](https://arxiv.org/pdf/2507.06261) of our most advanced model, [Gemini 2.5 pro](https://aistudio.google.com/app/prompts/new_chat), has just been published! 

   <b>June 2025</b>: The paper [Model Merging of Large Language Models](https://openreview.net/pdf?id=9sbetmvNpW) of our intern [Prateek Yadav](https://x.com/prateeky2806) has been accepted to Transactions on Machine Learning Research (TMLR). 

  <b>January 2025</b>: I am co-organizing [Repl4NLP 2025](https://sites.google.com/corp/view/repl4nlp2025/call-for-papers). The workshop will be co-located with NAACL 2025 in Albuquerque, New Mexico. 

  <b>December 2024</b>: My PhD thesis titled "Efficient Multilingual and Domain Adaptation of
Language Models under Resource Constraints" is now available [online](https://edoc.ub.uni-muenchen.de/34205/1/Chronopoulou_Alexandra.pdf). 

  <b>November 2024</b>: Excited to share that our paper [Language and Task Arithmetic with Parameter-Efficient Layers for Zero-Shot Summarization](https://arxiv.org/pdf/2311.09344) got <b>best paper award</b> at the Multilingual Representation Learning workshop at EMNLP 2024!

 <b>October 2024</b>: New preprint on [Model Merging of Large Language Models](https://arxiv.org/pdf/2410.03617).

  <b>October 2024</b>: Our paper [Language and Task Arithmetic with Parameter-Efficient Layers for Zero-Shot Summarization](https://arxiv.org/pdf/2311.09344) has been accepted to appear at the MRL workshop in EMNLP 2024! See you in Miami! ðŸŒ´

 <b>October 2024</b>: It's a wrap! ðŸŽ“ I successfully defended my PhD thesis on Efficient Multilingual and Domain Adaptation of Language Models under Resource Constraints. My thesis will (hopefully) be online soon! 


 <h2>Selected Publications</h2>

<ul class="sparse-list">
            <li>
          <b><a  href="https://arxiv.org/pdf/2507.06261">Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities </a></b> <br/> 
          Gemini Team, Google (I was one of the > 1000 authors)
          <br/>technical report<br/>
        </li>
            <li>
          <b><a  href="https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf">Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context </a></b> <br/> 
          Gemini Team, Google (I was one of the > 1000 authors)
          <br/>technical report<br/>
        </li>
            <li>
          <b><a  href="https://arxiv.org/abs/2311.09344.pdf">Language and Task Arithmetic with Parameter-Efficient Layers for Zero-Shot Summarization</a></b> <br/> 
          <b>Alexandra Chronopoulou</b>, <a href="https://pfeiffer.ai/">Jonas Pfeiffer</a>, <a href="https://scholar.google.com/citations?user=LdNDZRcAAAAJ&hl=en">Joshua Maynez</a>, <a href="https://cindyxinyiwang.github.io/">Xinyi Wang</a>, <a href="https://www.ruder.io/">Sebastian Ruder</a>, <a href="https://sites.google.com/site/priyankaagr17">Priyanka Agrawal</a>  <br/>
          EMNLP MRL Workshop 2024<br/>
        </li>
          <li>
          <b><a  href="https://aclanthology.org/2023.findings-eacl.153.pdf">AdapterSoup: Weight Averaging to Improve Generalization of Pretrained Language Models</a></b> [<a href="https://alexandra-chron.github.io/files/adaptersoup.pdf" class="link-in-list">slides</a>] <br/> 
          <b>Alexandra Chronopoulou</b>, <a href="https://scholar.google.com/citations?user=K5nCPZwAAAAJ&hl=en">Matthew E. Peters</a>, <a href="https://www.cis.uni-muenchen.de/~fraser/">Alexander Fraser</a>, <a href="https://jessedodge.github.io/">Jesse Dodge</a> <br/>
          EACL 2023 (Findings)<br/>
        </li>

</ul>


 <h2>More</h2>

- My undergrad thesis supervisor was [Alexandros Potamianos](https://slp-ntua.github.io/potam/). I spent a good part of 2018 and 2019 in the Speech and Language Processing group of ECE, NTUA. Thesis: [Transfer Learning with Deep Neural Networks for Sentiment Analysis and Semantic Modeling](https://alexandra-chron.github.io/files/thesis_achronopoulou.pdf). During my last undergrad year I was also working as a Machine Learning Engineer at [Behavioral Signal Technologies](https://behavioralsignals.com/). 

- I am from Athens, Greece (go VVV!) and I enjoy a variety of things including books, good movies, sports (tennis, padel, skiing), concerts, exploring new places, and most activities that are ocean-related. 
