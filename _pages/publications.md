---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

  You can also find my articles on my [Semantic Scholar](https://www.semanticscholar.org/author/Alexandra-Chronopoulou/3379701) or [Google Scholar](https://scholar.google.com/citations?hl=en&user=XiwRCRIAAAAJ&view_op=list_works&sortby=pubdate) profile.

Publications and arxiv preprints: 

<ul class="sparse-list">
          <li>
          <b>AdapterSoup: Weight Averaging to Improve Generalization of Pretrained Language Models</b> <br/>
          <u>Alexandra Chronopoulou</u>, [Matthew E. Peters](https://scholar.google.com/citations?user=K5nCPZwAAAAJ&hl=en), [Alexander Fraser](https://www.cis.uni-muenchen.de/~fraser/) and [Jesse Dodge](https://jessedodge.github.io/). <br/>
          EACL 2023 (findings).<br/>
        </li>
          <li>
          <b>m<sup>4</sup> Adapter: Multilingual Multi-Domain Adaptation for Machine Translation with a Meta-Adapter</b> <br/>
          [Wen Lai](https://lavine-lmu.github.io/), <u>Alexandra Chronopoulou</u> and [Alexander Fraser](https://www.cis.uni-muenchen.de/~fraser/). <br/>
          EMNLP 2022 (findings).<br/>[<a href="https://arxiv.org/abs/2210.11912">paper</a>]
          </li>
            <li>
          <b>Language-Family Adapters for Multilingual Neural Machine Translation</b> <br/>
          <u>Alexandra Chronopoulou</u>, [Dario Stojanovski](https://www.cis.lmu.de/~dario/) and [Alexander Fraser](https://www.cis.uni-muenchen.de/~fraser/). <br/>
          arxiv preprint.<br/>[<a href="https://arxiv.org/pdf/2209.15236.pdf">paper</a>]
          </li>
            <li>
          <b>Efficient Hierarchical Domain Adaptation for Pretrained Language Models</b> <br/>
          <u>Alexandra Chronopoulou</u>, [Matthew E. Peters](https://scholar.google.com/citations?user=K5nCPZwAAAAJ&hl=en) and [Jesse Dodge](https://jessedodge.github.io/). <br/>
          NAACL 2022.<br/>
          [<a href="https://aclanthology.org/2022.naacl-main.96.pdf">paper</a>]
          [<a href="https://github.com/alexandra-chron/hierarchical-domain-adaptation" class="link-in-list">code</a>]
          [<a href="https://blog.allenai.org/efficient-hierarchical-domain-adaptation-using-pretrained-language-models-fdd04c001230">blog</a>]
          [<a href="https://alexandra-chron.github.io/files/eff_hier_dom_adapt.pdf" class="link-in-list">slides</a>] 
        </li>
          <li>
          <b>Improving the Lexical Ability of Pretrained Language Models for Unsupervised Neural Machine Translation</b> <br/>
          <u>Alexandra Chronopoulou</u>, [Dario Stojanovski](https://www.cis.lmu.de/~dario/) and [Alexander Fraser](https://www.cis.uni-muenchen.de/~fraser/). <br/>
          NAACL 2021.<br/>
          [<a href="https://www.aclweb.org/anthology/2021.naacl-main.16.pdf">paper</a>]
          [<a href="https://github.com/alexandra-chron/lexical_xlm_relm" class="link-in-list">code</a>]
        </li>
        <li>
          <b>Reusing a Pretrained Language Model on Languages with Limited Corpora for Unsupervised NMT</b> <br/>
          <u>Alexandra Chronopoulou</u>, [Dario Stojanovski](https://www.cis.lmu.de/~dario/) and [Alexander Fraser](https://www.cis.uni-muenchen.de/~fraser/). <br/>
          EMNLP 2020.<br/>
          [<a href="https://www.aclweb.org/anthology/2020.emnlp-main.214.pdf" class="link-in-list">paper</a>]
          [<a href="https://github.com/alexandra-chron/relm_unmt" class="link-in-list">code</a>]
          [<a href="https://alexandra-chron.github.io/files/relm.pdf" class="link-in-list">slides</a>]
        </li>
        <li>
          <b>Domain Adversarial Fine-Tuning as an Effective Regularizer</b> <br/>
          [Giorgos Vernikos](https://georgevern.github.io/), [Katerina Margatina](https://katerinamargatina.github.io/), <u>Alexandra Chronopoulou</u> and [Ion Androutsopoulos](https://www2.aueb.gr/users/ion/). <br/>
          EMNLP 2020 (findings).<br/>
          [<a href="https://www.aclweb.org/anthology/2020.findings-emnlp.278.pdf" class="link-in-list">paper</a>]
          [<a href="https://github.com/GeorgeVern/AFTERV1.0" class="link-in-list">code</a>]
        </li>
        <li>
          <b>The LMU Munich System for the WMT 2020 Unsupervised Machine Translation Shared Task</b> <br/>
          <u>Alexandra Chronopoulou</u>, [Dario Stojanovski](https://www.cis.lmu.de/~dario/), [Viktor Hangya](https://www.cis.uni-muenchen.de/~hangyav/) and [Alexander Fraser](https://www.cis.uni-muenchen.de/~fraser/). <br/>
          WMT 2020.<br/>
          [<a href="https://www.aclweb.org/anthology/2020.wmt-1.128.pdf" class="link-in-list">paper</a>]
          [<a href="https://github.com/alexandra-chron/umt-lmu-wmt2020" class="link-in-list">code</a>]
          [<a href="https://drive.google.com/file/d/1gZvhZd5TW3z7VJubts13Y35L8H1mbBT1/view?usp=sharing" class="link-in-list">slides</a>]
         [<a href="https://drive.google.com/file/d/1bTjshwr8amPLyxlPzVDEcB6DtA4vjVUX/view?usp=sharing" class="link-in-list">poster</a>]
        </li>
        <li>
          <b>Transfer Learning with Deep Neural Networks for Sentiment Analysis and Semantic Modeling</b> <br/>
          <u>Alexandra Chronopoulou</u>. <br/>
          National Technical University of Athens.<br/>
          [<a href="https://alexandra-chron.github.io/files/thesis_achronopoulou.pdf">thesis (in English)</a>] 
          [<a href="https://dspace.lib.ntua.gr/xmlui/bitstream/handle/123456789/49039/diplomatiki_achronopoulou.pdf?sequence=1" class="link-in-list">thesis (in Greek)</a>]
        </li>
        <li>
          <b>An Embarrassingly Simple Approach for Transfer Learning from Pretrained Language Models</b> <br/>
          <u>Alexandra Chronopoulou</u>, [Christos Baziotis](https://cbaziotis.github.io/) and [Alexandros Potamianos](https://slp-ntua.github.io/potam/). <br/>
          NAACL 2019.<br/>
          [<a href="https://www.aclweb.org/anthology/N19-1213.pdf" class="link-in-list">paper</a>]
          [<a href="https://github.com/alexandra-chron/siatl" class="link-in-list">code</a>]
        </li>
        <li>
          <b>NTUA-SLP at IEST 2018: Ensemble of neural transfer methods for implicit emotion classification</b> <br/>
          <u>Alexandra Chronopoulou</u>, [Katerina Margatina](https://katerinamargatina.github.io/), [Christos Baziotis](https://cbaziotis.github.io/) and [Alexandros Potamianos](https://slp-ntua.github.io/potam/). <br/>
          WASSA 2018.<br />
          [<a href="https://www.aclweb.org/anthology/W18-6209.pdf" class="link-in-list">paper</a>]
          [<a href="https://github.com/alexandra-chron/ntua-slp-wassa-iest2018">code</a>]
        </li>
        <li>
          <b>NTUA-SLP at SemEval-2018 Task 1: Predicting Affective Content in Tweets with Deep Attentive RNNs and Transfer Learning</b> <br/>
          [Christos Baziotis](https://cbaziotis.github.io/), [Nikos Athanasiou](https://is.mpg.de/employees/nathanasiou), <u>Alexandra Chronopoulou</u>, [Athanasia Kolovou](https://scholar.google.gr/citations?user=V8gp47MAAAAJ&hl=en), [Georgios Paraskevopoulos](https://georgepar.github.io/), [Nikolaos Ellinas](https://scholar.google.gr/citations?user=y329tukAAAAJ&hl=en), [Shrikanth Narayanan](https://sail.usc.edu/people/shri.html) and [Alexandros Potamianos](https://slp-ntua.github.io/potam/). <br/>
          SemEval 2018. <br />
          [<a href="https://www.aclweb.org/anthology/S18-1037.pdf" class="link-in-list">paper</a>]
          [<a href="https://github.com/cbaziotis/ntua-slp-semeval2018" class="link-in-list">code</a>]
        </li>
</ul>
